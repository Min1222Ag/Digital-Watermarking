{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkjR730lS/2qDRoq+SeI1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Min1222Ag/Digital-Watermarking/blob/main/model_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO > CRNN : 말풍선 탐지"
      ],
      "metadata": {
        "id": "bKgz-1nnxRoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. YOLO로 말풍선 탐지\n",
        "2. CRNN으로 텍스트 탐지"
      ],
      "metadata": {
        "id": "h26x2DjfFxzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "def load_model():\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def detect_balloons(image_path, model):\n",
        "    image = Image.open(image_path)\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    predictions = model(image)\n",
        "\n",
        "    # 말풍선을 위한 클래스 ID 확인 필요 (일반적으로 클래스 ID는 데이터셋에 따라 다름)\n",
        "    # 예제에서는 임의의 클래스 ID를 사용\n",
        "    balloon_id = 91  # 예시 ID, 실제 ID는 데이터셋에 따라 다름\n",
        "    pred_class = [int(i) for i in list(predictions[0]['labels'])]\n",
        "    pred_boxes = [[(i[0], i[1], i[2], i[3]) for i in list(predictions[0]['boxes'])]]\n",
        "    pred_score = list(predictions[0]['scores'])\n",
        "\n",
        "    # 스코어가 0.5 이상인 말풍선만 선택\n",
        "    balloon_boxes = [pred_boxes[i] for i in range(len(pred_score)) if pred_score[i] > 0.5 and pred_class[i] == balloon_id]\n",
        "    return balloon_boxes\n",
        "\n",
        "model = load_model()\n",
        "balloon_boxes = detect_balloons('path_to_image.jpg', model)"
      ],
      "metadata": {
        "id": "1MAoiiRZ7Dx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "def extract_text_from_balloons(image_path, balloon_boxes):\n",
        "    image = cv2.imread(image_path)\n",
        "    texts = []\n",
        "    for box in balloon_boxes:\n",
        "        roi = image[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
        "        text = pytesseract.image_to_string(roi, lang='kor+eng')\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "texts = extract_text_from_balloons('path_to_image.jpg', balloon_boxes)\n"
      ],
      "metadata": {
        "id": "nj7qzYhaGXR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_watermark(texts, balloon_boxes, image_path):\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.truetype(\"arial.ttf\", 14)  # 폰트와 크기는 조절 가능\n",
        "\n",
        "    for text, box in zip(texts, balloon_boxes):\n",
        "        draw.text((box[0], box[1]), text, font=font, fill=(255,0,0))\n",
        "\n",
        "    image.save('watermarked_image.jpg')\n",
        "\n",
        "insert_watermark(texts, balloon_boxes, 'path_to_image.jpg')\n"
      ],
      "metadata": {
        "id": "IzHc0m22GZ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO > CRNN : 텍스트 탐지"
      ],
      "metadata": {
        "id": "E_QTXzmHxX0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless numpy"
      ],
      "metadata": {
        "id": "yYP8yJrexet3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_pretrained_east_model():\n",
        "    # EAST 모델 파일 경로\n",
        "    model_path = 'frozen_east_text_detection.pb'\n",
        "    return cv2.dnn.readNet(model_path)\n",
        "\n",
        "def detect_text(image_path, net, confThreshold=0.5, nmsThreshold=0.4):\n",
        "    image = cv2.imread(image_path)\n",
        "    orig_image = image.copy()\n",
        "    (H, W) = image.shape[:2]\n",
        "\n",
        "    # EAST 모델은 입력 이미지의 크기가 32의 배수가 되어야 합니다.\n",
        "    newW, newH = (320, 320)\n",
        "    rW = W / float(newW)\n",
        "    rH = H / float(newH)\n",
        "\n",
        "    # 이미지 전처리\n",
        "    blob = cv2.dnn.blobFromImage(image, 1.0, (newW, newH), (123.68, 116.78, 103.94), True, False)\n",
        "    net.setInput(blob)\n",
        "    (scores, geometry) = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"])\n",
        "\n",
        "    # 텍스트 검출 및 NMS 적용\n",
        "    (rects, confidences) = decode_predictions(scores, geometry, confThreshold)\n",
        "    indices = cv2.dnn.NMSBoxesRotated(rects, confidences, confThreshold, nmsThreshold)\n",
        "    detections = []\n",
        "\n",
        "    # 검출된 텍스트 영역 처리\n",
        "    for i in indices:\n",
        "        vertices = cv2.boxPoints(rects[i[0]])\n",
        "        for j in range(4):\n",
        "            vertices[j][0] *= rW\n",
        "            vertices[j][1] *= rH\n",
        "        detections.append(vertices)\n",
        "    return orig_image, detections\n",
        "\n",
        "def decode_predictions(scores, geometry, confThreshold):\n",
        "    (numRows, numCols) = scores.shape[2:4]\n",
        "    rects = []\n",
        "    confidences = []\n",
        "\n",
        "    for y in range(0, numRows):\n",
        "        scoresData = scores[0, 0, y]\n",
        "        xData0 = geometry[0, 0, y]\n",
        "        xData1 = geometry[0, 1, y]\n",
        "        xData2 = geometry[0, 2, y]\n",
        "        xData3 = geometry[0, 3, y]\n",
        "        anglesData = geometry[0, 4, y]\n",
        "\n",
        "        for x in range(0, numCols):\n",
        "            if scoresData[x] < confThreshold:\n",
        "                continue\n",
        "\n",
        "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
        "            angle = anglesData[x]\n",
        "            cos = np.cos(angle)\n",
        "            sin = np.sin(angle)\n",
        "            h = xData0[x] + xData1[x]\n",
        "            w = xData2[x] + xData3[x]\n",
        "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
        "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
        "            startX = int(endX - w)\n",
        "            startY = int(endY - h)\n",
        "            rects.append(cv2.rotatedRectangle(startX, startY, int(w), int(h), -angle * 180.0 / np.pi))\n",
        "            confidences.append(scoresData[x])\n",
        "    return (rects, confidences)\n",
        "\n",
        "# 모델 로드\n",
        "net = load_pretrained_east_model()\n",
        "\n",
        "# 이미지에서 텍스트 검출\n",
        "image_path = 'path_to_your_image.jpg'\n",
        "original_image, detections = detect_text(image_path, net) # detection 변수에 텍스트 검출 영역이 할당됌\n",
        "\n"
      ],
      "metadata": {
        "id": "wn2HgSPax0jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_dct_watermark(image, detections, watermark_text, alpha=0.01):\n",
        "    # 이미지를 회색조로 변환\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    watermarked_image = gray.copy().astype(np.float32)\n",
        "\n",
        "    # 워터마크 텍스트를 각 텍스트 영역에 삽입\n",
        "    for vertices in detections:\n",
        "        # 각 영역의 경계를 계산\n",
        "        x, y, w, h = cv2.boundingRect(vertices)\n",
        "        # 영역 내부에 워터마크 적용\n",
        "        roi = gray[y:y+h, x:x+w]\n",
        "        roi_dct = cv2.dct(roi.astype(np.float32))\n",
        "        watermark = np.zeros_like(roi, dtype=np.float32)\n",
        "        cv2.putText(watermark, watermark_text, (0, h // 2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 255, 1)\n",
        "        watermark_dct = cv2.dct(watermark)\n",
        "        roi_dct += alpha * watermark_dct\n",
        "        watermarked_roi = cv2.idct(roi_dct)\n",
        "\n",
        "        # 워터마킹된 ROI를 원본 이미지에 복사\n",
        "        watermarked_image[y:y+h, x:x+w] = watermarked_roi\n",
        "\n",
        "    # 결과 이미지는 uint8로 변환\n",
        "    watermarked_image = np.clip(watermarked_image, 0, 255).astype(np.uint8)\n",
        "    return watermarked_image\n",
        "\n",
        "# 워터마크를 적용\n",
        "watermarked_image = apply_dct_watermark(original_image, detections, 'Secret', alpha=0.01)\n",
        "\n",
        "# 결과 이미지 저장\n",
        "cv2.imwrite('watermarked_image.jpg', watermarked_image)\n"
      ],
      "metadata": {
        "id": "DRhr8rh3zKeI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}